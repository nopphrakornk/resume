{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "import heapq\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_df = pd.read_csv('data/webpage_rec_data/census.csv')\n",
    "content_df = pd.read_csv('data/webpage_rec_data/content.csv')\n",
    "test = pd.read_csv('data/webpage_rec_data/test.csv')\n",
    "train = pd.read_csv('data/webpage_rec_data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['URL_PATH'] = test['URL_PATH'].apply(lambda x: '/'+ x.lstrip('/en'))\n",
    "test = test.reindex(index=test.index[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(344914, 4) (147820, 4)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "\n",
    "class AbstractRecommender(ABC):\n",
    "    @abstractmethod\n",
    "    def observe(self, user_interaction):\n",
    "        \"\"\"Observe user interaction event as a Pandas Series.\"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def recommend(self, user_id, n):\n",
    "        \"\"\"Return a list of n recommendations for a given user.\"\"\"\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TFIDF Accuracy: 8.60%\n",
    "\n",
    "Random Accuracy: 28.92%\n",
    "\n",
    "Popularity Accuracy: 30.94%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF\n",
    "Reccomend using top n similar content to the user's latest viewed page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFIDFRecommender(AbstractRecommender):\n",
    "    def __init__(self):\n",
    "        self.last_page_viewed = None\n",
    "        self.vectorizer = None\n",
    "        self.fitter = None\n",
    "        self.contents = None\n",
    "        self.top_pages = None\n",
    "        \n",
    "    def observe(self, new_page):\n",
    "        self.last_page_viewed[new_page['USER_ID']] = new_page['URL_PATH']\n",
    "        \n",
    "    def recommend(self, user_id, n):\n",
    "        if user_id in self.last_page_viewed:\n",
    "            last_viewed_page = self.last_page_viewed[user_id]\n",
    "            if last_viewed_page in self.contents.index:\n",
    "                data = self.contents.loc[last_viewed_page]\n",
    "                trans_text = self.vectorizer.transform([data])\n",
    "                cosine_similarities = linear_kernel(trans_text, self.fitter).flatten()\n",
    "                doc_index = self.contents.index.get_loc(last_viewed_page)\n",
    "                cosine_similarities[doc_index] = -1\n",
    "                related_docs_indices = cosine_similarities.argsort()[:-n-1:-1]\n",
    "                return self.contents.iloc[related_docs_indices].index.values\n",
    "            else:\n",
    "                return np.random.choice(self.top_pages,n)    \n",
    "        else:\n",
    "            return np.random.choice(self.top_pages,n)\n",
    "\n",
    "    def train(self, content, train):\n",
    "        self.vectorizer = TfidfVectorizer()\n",
    "        content= content[['url', 'title', 'article_content']].dropna()\n",
    "        self.contents = content['title'] + ' ' + content['article_content']\n",
    "        self.contents.index = content['url']\n",
    "        self.fitter = self.vectorizer.fit_transform(self.contents)\n",
    "\n",
    "        train['URL_PATH'] = train['URL_PATH'].apply(lambda x: '/' + x.lstrip('/en'))\n",
    "        self.top_pages = train['URL_PATH'].value_counts().index[:10]\n",
    "        first_encounter_df = train.drop_duplicates(subset='USER_ID', keep='first')\n",
    "        self.last_page_viewed = first_encounter_df.set_index('USER_ID')['URL_PATH'].to_dict()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random user history\n",
    "Reccomend using from randoming n pages from user's history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomHistoryRecommender(AbstractRecommender):\n",
    "    def __init__(self):\n",
    "        self.user_interactions = None\n",
    "\n",
    "    def observe(self, new_user_interaction):\n",
    "        self.user_interactions.loc[len(self.user_interactions)] = new_user_interaction\n",
    "\n",
    "    def recommend(self, user_id, n):\n",
    "        user_interaction = self.user_interactions[self.user_interactions['USER_ID'] == str(user_id)]['URL_PATH']\n",
    "        if user_interaction.shape[0] == 0:\n",
    "            available_items = self.user_interactions['URL_PATH'].nunique()\n",
    "            n = min(n, available_items)  # Ensure n doesn't exceed the number of available items\n",
    "            return self.user_interactions['URL_PATH'].sample(n).values\n",
    "        \n",
    "        probabilities = user_interaction.value_counts(normalize=True)\n",
    "        \n",
    "        n = min(n, len(probabilities))\n",
    "        \n",
    "        return np.random.choice(probabilities.index, size=n, p=probabilities.values, replace=False)\n",
    "\n",
    "\n",
    "    def train(self, train_df):\n",
    "        self.user_interactions = train_df.copy()\n",
    "        self.user_interactions['URL_PATH'] = self.user_interactions['URL_PATH'].apply(lambda x: '/' + x.lstrip('/en'))\n",
    "        self.user_interactions = self.user_interactions.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Popularity with time decay\n",
    "popularity = $\\sum\\frac{1}{1+ \\alpha(T-t)}$; page popularity diminishes over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_popularity(T, t, alpha):\n",
    "    return 1 / (1 + alpha * (T - t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recommender(AbstractRecommender):\n",
    "    def __init__(self):\n",
    "        # Track the last page viewed per user\n",
    "        self.last_page_viewed = {}\n",
    "\n",
    "        # Popularity data per user\n",
    "        # 'user_id: {url_path: [popularity, last_row_num]}'\n",
    "        self.user_time_popularity = {}\n",
    "\n",
    "        # Popularity heap per user\n",
    "        # 'user_id: [(popularity, url_path)]'\n",
    "        self.user_popularity_heap = {}\n",
    "\n",
    "        self.alpha = 0.1\n",
    "\n",
    "    def observe(self, user_interaction):\n",
    "        # Extract user_id and URL path from the interaction\n",
    "        user_id = user_interaction[\"USER_ID\"]\n",
    "        url_path = user_interaction[\"URL_PATH\"]\n",
    "        row_number = user_interaction['ROW_NUM']\n",
    "\n",
    "        # Initialize data structures for the user if they don't exist\n",
    "        if user_id not in self.user_time_popularity:\n",
    "            self.user_time_popularity[user_id] = {}\n",
    "            self.user_popularity_heap[user_id] = []\n",
    "\n",
    "        user_popularity = self.user_time_popularity[user_id]\n",
    "\n",
    "        # Update popularity for the URL path for the specific user\n",
    "        if url_path in user_popularity:\n",
    "            tmp = user_popularity[url_path]\n",
    "            t = tmp[1]\n",
    "            popularity = time_popularity(row_number, t, self.alpha)\n",
    "            tmp[0] += popularity\n",
    "            tmp[1] = row_number\n",
    "            heapq.heapify(self.user_popularity_heap[user_id])\n",
    "        else:\n",
    "            popularity = time_popularity(row_number, row_number, self.alpha)\n",
    "            tmp = [popularity, row_number, url_path]\n",
    "            user_popularity[url_path] = tmp\n",
    "            heapq.heappush(self.user_popularity_heap[user_id], tmp)\n",
    "\n",
    "    def recommend(self, user_id, n):\n",
    "        # Check if the user has any interaction data\n",
    "        if user_id not in self.user_popularity_heap:\n",
    "            return []\n",
    "\n",
    "        # Get the top 'n' most popular items for the specific user\n",
    "        result = heapq.nlargest(n, self.user_popularity_heap[user_id])\n",
    "        return [i[2] for i in result]\n",
    "\n",
    "    def train(self, user_interactions):\n",
    "        for _, s in user_interactions.iterrows():\n",
    "            self.observe(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Test...\n"
     ]
    }
   ],
   "source": [
    "n = 3\n",
    "tfidf_recommender = TFIDFRecommender()\n",
    "random_recommender = RandomHistoryRecommender()\n",
    "popularity_recommender = Recommender()\n",
    "\n",
    "train\n",
    "print('Train...')\n",
    "tfidf_recommender.train(content_df, train)\n",
    "random_recommender.train(train)\n",
    "popularity_recommender.train(train.reindex(index=train.index[::-1]))\n",
    "\n",
    "total_num = 0\n",
    "tfidf_right_prediction = 0\n",
    "random_right_prediction = 0\n",
    "popularity_right_prediction = 0\n",
    "\n",
    "\n",
    "print('Test...')\n",
    "for _, r in test.iterrows():\n",
    "    user_id_str = str(r['USER_ID'])\n",
    "    tfidf_rec = tfidf_recommender.recommend(user_id_str, 3)\n",
    "    rand_rec = random_recommender.recommend(user_id_str, 3)\n",
    "    pop_rec = popularity_recommender.recommend(user_id_str, 3)\n",
    "\n",
    "    true_path = r['URL_PATH']\n",
    "    tfidf_right_prediction += int(true_path in tfidf_rec)\n",
    "    random_right_prediction += int(true_path in rand_rec)\n",
    "    popularity_right_prediction += int(true_path in pop_rec)\n",
    "\n",
    "    tfidf_recommender.observe(r)\n",
    "    random_recommender.observe(r)\n",
    "    popularity_recommender.observe(r)\n",
    "    total_num += 1\n",
    "    # if total_num % 50000 == 0:\n",
    "    #     tfidf_accuracy = tfidf_right_prediction / total_num\n",
    "    #     random_accuracy = random_right_prediction / total_num\n",
    "    #     popularity_accuracy = popularity_right_prediction / total_num\n",
    "\n",
    "    #     print(f\"TFIDF Accuracy: {tfidf_accuracy:.2%}\")\n",
    "    #     print(f\"Random Accuracy: {random_accuracy:.2%}\")\n",
    "    #     print(f\"Popularity Accuracy: {popularity_accuracy:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDF Accuracy: 8.60%\n",
      "Random Accuracy: 28.92%\n",
      "Popularity Accuracy: 30.94%\n"
     ]
    }
   ],
   "source": [
    "tfidf_accuracy = tfidf_right_prediction / total_num\n",
    "random_accuracy = random_right_prediction / total_num\n",
    "popularity_accuracy = popularity_right_prediction / total_num\n",
    "\n",
    "print(f\"TFIDF Accuracy: {tfidf_accuracy:.2%}\")\n",
    "print(f\"Random Accuracy: {random_accuracy:.2%}\")\n",
    "print(f\"Popularity Accuracy: {popularity_accuracy:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
